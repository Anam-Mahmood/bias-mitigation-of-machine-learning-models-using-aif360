{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This notebook demonstrates how to Identify & Remove Bias during the \"Pre-Processing Stage\" using the AI Fairness 360 Toolkit by adjusting the weights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing algorithm\n",
    "A bias mitigation algorithm that is applied to training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @hidden_cell\n",
    "# The following code contains the credentials for a file in your IBM Cloud Object Storage.\n",
    "# You might want to remove those credentials before you share your notebook.\n",
    "credentials = {\n",
    "    'IAM_SERVICE_ID': 'IAM_SERVICE_ID',\n",
    "    'IBM_API_KEY_ID': 'IBM_API_KEY_ID',\n",
    "    'ENDPOINT': 'https://s3-api.us-geo.objectstorage.service.networklayer.com',\n",
    "    'IBM_AUTH_ENDPOINT': 'https://iam.cloud.ibm.com/oidc/token',\n",
    "    'BUCKET': 'ai360series-donotdelete-pr-1zay1c1uizeatc',\n",
    "    'FILE': 'Pipeline_LabelEncoder-0.1.zip'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_botocore.client import Config\n",
    "import ibm_boto3\n",
    "\n",
    "cos = ibm_boto3.client(service_name='s3',\n",
    "    ibm_api_key_id=credentials['IBM_API_KEY_ID'],\n",
    "    ibm_service_instance_id=credentials['IAM_SERVICE_ID'],\n",
    "    ibm_auth_endpoint=credentials['IBM_AUTH_ENDPOINT'],\n",
    "    config=Config(signature_version='oauth'),\n",
    "    endpoint_url=credentials['ENDPOINT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos.download_file(Bucket=credentials['BUCKET'],Key='Pipeline_LabelEncoder-0.1.zip',Filename='/home/wsuser/work/Pipeline_LabelEncoder-0.1.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install Pipeline_LabelEncoder-0.1.zip\n",
    "!pip install aif360"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install 'tensorflow>=1.13.1,< 2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from aif360.metrics import BinaryLabelDatasetMetric\n",
    "from aif360.datasets import BinaryLabelDataset\n",
    "from IPython.display import Markdown, display\n",
    "from aif360.algorithms.preprocessing.reweighing import Reweighing\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is where you import your DataFrame. Delete everything in this cell below this comment. \n",
    "# Import your data with \"Find and add data\" in the top right 0100 icon. \n",
    "# Select \"Insert to code => pandas DataFrame\" under the data you want to import.\n",
    "\n",
    "import types\n",
    "import pandas as pd\n",
    "from botocore.client import Config\n",
    "import ibm_boto3\n",
    "\n",
    "def __iter__(self): return 0\n",
    "\n",
    "# @hidden_cell\n",
    "# The following code accesses a file in your IBM Cloud Object Storage. It includes your credentials.\n",
    "# You might want to remove those credentials before you share the notebook.\n",
    "client_46fb316bd6aa42a880152b79a0bc6af1 = ibm_boto3.client(service_name='s3',\n",
    "    ibm_api_key_id='IBM_API_KEY_ID',\n",
    "    ibm_auth_endpoint=\"https://iam.cloud.ibm.com/oidc/token\",\n",
    "    config=Config(signature_version='oauth'),\n",
    "    endpoint_url='https://s3-api.us-geo.objectstorage.service.networklayer.com')\n",
    "\n",
    "body = client_46fb316bd6aa42a880152b79a0bc6af1.get_object(Bucket='aifairness360-donotdelete-pr-jf2oqgkybwubjd',Key='fraud_data.csv')['Body']\n",
    "# add missing __iter__ method, so pandas accepts body as file-like object\n",
    "if not hasattr(body, \"__iter__\"): body.__iter__ = types.MethodType( __iter__, body )\n",
    "\n",
    "df_data_2 = pd.read_csv(body)\n",
    "df_data_2.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "privileged_groups = [{'Gender': 1}]\n",
    "unprivileged_groups = [{'Gender': 0}]\n",
    "favorable_label = 1 \n",
    "unfavorable_label = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "categorical_column = ['Gender', 'Married', 'Fraud_risk']\n",
    "\n",
    "data_encoded = df_data_1.copy(deep=True)\n",
    "#Use Scikit-learn label encoding to encode character data\n",
    "lab_enc = preprocessing.LabelEncoder()\n",
    "for col in categorical_column:\n",
    "        data_encoded[col] = lab_enc.fit_transform(df_data_1[col])\n",
    "        le_name_mapping = dict(zip(lab_enc.classes_, lab_enc.transform(lab_enc.classes_)))\n",
    "        print('Feature', col)\n",
    "        print('mapping', le_name_mapping)\n",
    "        \n",
    "\n",
    "data_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Pipeline_LabelEncoder.sklearn_label_encoder import PipelineLabelEncoder\n",
    "preprocessed_data = PipelineLabelEncoder(columns = ['Gender','Married', 'Fraud_risk']).fit_transform(data_encoded)\n",
    "print('-------------------------')\n",
    "#print('validation data encoding')\n",
    "#validation_enc_data = PipelineLabelEncoder(columns = ['Gender','Married', 'Fraud_risk']).transform(validation_input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create binary label dataset that can be used by bias mitigation algorithms\n",
    "fraud_dataset = BinaryLabelDataset(favorable_label=favorable_label,\n",
    "                                unfavorable_label=unfavorable_label,\n",
    "                                df=preprocessed_data,\n",
    "                                label_names=['Fraud_risk'],\n",
    "                                protected_attribute_names=['Gender', 'Married'],\n",
    "                                unprivileged_protected_attributes=unprivileged_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(\"#### Training Data Details\"))\n",
    "print(\"shape of the training dataset\", fraud_dataset.features.shape)\n",
    "print(\"Training data favorable label\", fraud_dataset.favorable_label)\n",
    "print(\"Training data unfavorable label\", fraud_dataset.unfavorable_label)\n",
    "print(\"Training data protected attribute\", fraud_dataset.protected_attribute_names)\n",
    "print(\"Training data privileged protected attribute (1:Male and 0:Female)\", \n",
    "      fraud_dataset.privileged_protected_attributes)\n",
    "print(\"Training data unprivileged protected attribute (1:Male and 0:Female)\",\n",
    "      fraud_dataset.unprivileged_protected_attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_orig_train = BinaryLabelDatasetMetric(fraud_dataset, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "print(\"Difference in mean outcomes between unprivileged and privileged groups = %f\" % \n",
    "      metric_orig_train.mean_difference())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RW = Reweighing(unprivileged_groups=unprivileged_groups,\n",
    "               privileged_groups=privileged_groups)\n",
    "RW.fit(fraud_dataset)\n",
    "train_tf_dataset = RW.transform(fraud_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tf_dataset.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_orig_train = BinaryLabelDatasetMetric(train_tf_dataset, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "\n",
    "print(\"Difference in mean outcomes between unprivileged and privileged groups = %f\"\n",
    "      % metric_orig_train.mean_difference())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## There's no unfair advantage between the unprivileged and privileged groups."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
