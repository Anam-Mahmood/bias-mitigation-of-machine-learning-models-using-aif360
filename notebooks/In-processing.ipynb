{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This Notebook demonstrates how to reduce the bias during \"In-processing\" stage using AI 360 Fairness toolkit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In-processing algorithm\n",
    "A bias mitigation algorithm that is applied to a model during its training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insert your credentials as credentials in the below cell\n",
    "Click on dropdown from Pipeline_LabelEncoder-0.1.zip under Data tab and select 'Credentials'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# @hidden_cell\n",
    "# The following code contains the credentials for a file in your IBM Cloud Object Storage.\n",
    "# You might want to remove those credentials before you share your notebook.\n",
    "credentials = {\n",
    "\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_botocore.client import Config\n",
    "import ibm_boto3\n",
    "\n",
    "cos = ibm_boto3.client(service_name='s3',\n",
    "    ibm_api_key_id=credentials['IBM_API_KEY_ID'],\n",
    "    ibm_service_instance_id=credentials['IAM_SERVICE_ID'],\n",
    "    ibm_auth_endpoint=credentials['IBM_AUTH_ENDPOINT'],\n",
    "    config=Config(signature_version='oauth'),\n",
    "    endpoint_url=credentials['ENDPOINT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/wsuser/work'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cos.download_file(Bucket=credentials['BUCKET'],Key='Pipeline_LabelEncoder-0.1.zip',Filename='/home/wsuser/work/Pipeline_LabelEncoder-0.1.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline_LabelEncoder-0.1.zip\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ./Pipeline_LabelEncoder-0.1.zip\n",
      "Building wheels for collected packages: Pipeline-LabelEncoder\n",
      "  Building wheel for Pipeline-LabelEncoder (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for Pipeline-LabelEncoder: filename=Pipeline_LabelEncoder-0.1-py3-none-any.whl size=2062 sha256=b95c58092dbee1a7d1b40be64a83325ef885fc18e3d12798b74d8ae963b937a3\n",
      "  Stored in directory: /tmp/wsuser/.cache/pip/wheels/a1/1a/b1/66d8f1917ec5b09eb70adf911c60dec54820888fd7cb9941ad\n",
      "Successfully built Pipeline-LabelEncoder\n",
      "Installing collected packages: Pipeline-LabelEncoder\n",
      "  Attempting uninstall: Pipeline-LabelEncoder\n",
      "    Found existing installation: Pipeline-LabelEncoder 0.1\n",
      "    Uninstalling Pipeline-LabelEncoder-0.1:\n",
      "      Successfully uninstalled Pipeline-LabelEncoder-0.1\n",
      "Successfully installed Pipeline-LabelEncoder-0.1\n",
      "Requirement already satisfied: aif360 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (0.3.0)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from aif360) (3.2.2)\n",
      "Requirement already satisfied: pandas>=0.24.0 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from aif360) (1.0.5)\n",
      "Requirement already satisfied: scikit-learn>=0.21 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from aif360) (0.23.1)\n",
      "Requirement already satisfied: numpy>=1.16 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from aif360) (1.18.5)\n",
      "Requirement already satisfied: scipy>=1.2.0 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from aif360) (1.5.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from matplotlib->aif360) (2.4.7)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from matplotlib->aif360) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from matplotlib->aif360) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from matplotlib->aif360) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from pandas>=0.24.0->aif360) (2020.1)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from scikit-learn>=0.21->aif360) (0.16.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from scikit-learn>=0.21->aif360) (2.1.0)\n",
      "Requirement already satisfied: six in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from cycler>=0.10->matplotlib->aif360) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install Pipeline_LabelEncoder-0.1.zip\n",
    "!pip install aif360"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.15.4'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow<2,>=1.13.1 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (1.15.4)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from tensorflow<2,>=1.13.1) (1.1.0)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from tensorflow<2,>=1.13.1) (1.12.1)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from tensorflow<2,>=1.13.1) (1.27.2)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from tensorflow<2,>=1.13.1) (3.12.3)\n",
      "Requirement already satisfied: gast==0.2.2 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from tensorflow<2,>=1.13.1) (0.2.2)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from tensorflow<2,>=1.13.1) (0.2.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from tensorflow<2,>=1.13.1) (3.1.0)\n",
      "Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from tensorflow<2,>=1.13.1) (1.15.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from tensorflow<2,>=1.13.1) (1.15.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from tensorflow<2,>=1.13.1) (1.1.0)\n",
      "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from tensorflow<2,>=1.13.1) (0.34.2)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from tensorflow<2,>=1.13.1) (0.9.0)\n",
      "Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from tensorflow<2,>=1.13.1) (1.18.5)\n",
      "Requirement already satisfied: astor>=0.6.0 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from tensorflow<2,>=1.13.1) (0.8.0)\n",
      "Requirement already satisfied: tensorflow-estimator==1.15.1 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from tensorflow<2,>=1.13.1) (1.15.1)\n",
      "Requirement already satisfied: keras-applications>=1.0.8 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from tensorflow<2,>=1.13.1) (1.0.8)\n",
      "Requirement already satisfied: setuptools in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from protobuf>=3.6.1->tensorflow<2,>=1.13.1) (47.3.1.post20200622)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow<2,>=1.13.1) (3.1.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow<2,>=1.13.1) (1.0.1)\n",
      "Requirement already satisfied: h5py in /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages (from keras-applications>=1.0.8->tensorflow<2,>=1.13.1) (2.10.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install 'tensorflow>=1.13.1,< 2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# Load all necessary packages\n",
    "import pandas as pd\n",
    "from aif360.datasets import BinaryLabelDataset\n",
    "from aif360.metrics import BinaryLabelDatasetMetric\n",
    "from aif360.metrics import ClassificationMetric\n",
    "from aif360.metrics.utils import compute_boolean_conditioning_vector\n",
    "\n",
    "from aif360.algorithms.inprocessing.adversarial_debiasing import AdversarialDebiasing\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler, MaxAbsScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insert the data as Pandas Dataframe and change the name from df_data_ to df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Married</th>\n",
       "      <th>Education</th>\n",
       "      <th>Fraud_risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>Risk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>Safe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>Safe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Male</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>Safe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>Risk</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Gender Married  Education Fraud_risk\n",
       "0   Male      No          1       Risk\n",
       "1   Male     Yes          1       Safe\n",
       "2   Male     Yes          1       Safe\n",
       "3   Male     Yes          0       Safe\n",
       "4   Male      No          1       Risk"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import types\n",
    "import pandas as pd\n",
    "from botocore.client import Config\n",
    "import ibm_boto3\n",
    "\n",
    "def __iter__(self): return 0\n",
    "\n",
    "# @hidden_cell\n",
    "# The following code accesses a file in your IBM Cloud Object Storage. It includes your credentials.\n",
    "# You might want to remove those credentials before you share the notebook.\n",
    "client_943f0d0348cb4b5fb50f9c338e8d8cc1 = ibm_boto3.client(service_name='s3',\n",
    "    ibm_api_key_id='mecmxiDlkkNBAx_xwFoWofXDFgfjwrYliwcdLryqmvu7',\n",
    "    ibm_auth_endpoint=\"https://iam.cloud.ibm.com/oidc/token\",\n",
    "    config=Config(signature_version='oauth'),\n",
    "    endpoint_url='https://s3-api.us-geo.objectstorage.service.networklayer.com')\n",
    "\n",
    "body = client_943f0d0348cb4b5fb50f9c338e8d8cc1.get_object(Bucket='ai360series-donotdelete-pr-1zay1c1uizeatc',Key='fraud_data.csv')['Body']\n",
    "# add missing __iter__ method, so pandas accepts body as file-like object\n",
    "if not hasattr(body, \"__iter__\"): body.__iter__ = types.MethodType( __iter__, body )\n",
    "\n",
    "df = pd.read_csv(body)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Married</th>\n",
       "      <th>Education</th>\n",
       "      <th>Fraud_risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>921</td>\n",
       "      <td>921</td>\n",
       "      <td>921.000000</td>\n",
       "      <td>921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Safe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>703</td>\n",
       "      <td>501</td>\n",
       "      <td>NaN</td>\n",
       "      <td>562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.730727</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.443823</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Gender Married   Education Fraud_risk\n",
       "count     921     921  921.000000        921\n",
       "unique      2       2         NaN          2\n",
       "top      Male      No         NaN       Safe\n",
       "freq      703     501         NaN        562\n",
       "mean      NaN     NaN    0.730727        NaN\n",
       "std       NaN     NaN    0.443823        NaN\n",
       "min       NaN     NaN    0.000000        NaN\n",
       "25%       NaN     NaN    0.000000        NaN\n",
       "50%       NaN     NaN    1.000000        NaN\n",
       "75%       NaN     NaN    1.000000        NaN\n",
       "max       NaN     NaN    1.000000        NaN"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(include = 'all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "privileged_groups = [{'Gender': 1}]\n",
    "unprivileged_groups = [{'Gender': 0}]\n",
    "favorable_label = 1 \n",
    "unfavorable_label = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Gender\n",
      "mapping {'Female': 0, 'Male': 1}\n",
      "Feature Married\n",
      "mapping {'No': 0, 'Yes': 1}\n",
      "Feature Fraud_risk\n",
      "mapping {'Risk': 0, 'Safe': 1}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Married</th>\n",
       "      <th>Education</th>\n",
       "      <th>Fraud_risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Gender  Married  Education  Fraud_risk\n",
       "0       1        0          1           0\n",
       "1       1        1          1           1\n",
       "2       1        1          1           1\n",
       "3       1        1          0           1\n",
       "4       1        0          1           0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "categorical_column = ['Gender', 'Married', 'Fraud_risk']\n",
    "\n",
    "data_encoded = df.copy(deep=True)\n",
    "#Use Scikit-learn label encoding to encode character data\n",
    "lab_enc = preprocessing.LabelEncoder()\n",
    "for col in categorical_column:\n",
    "        data_encoded[col] = lab_enc.fit_transform(df[col])\n",
    "        le_name_mapping = dict(zip(lab_enc.classes_, lab_enc.transform(lab_enc.classes_)))\n",
    "        print('Feature', col)\n",
    "        print('mapping', le_name_mapping)\n",
    "        \n",
    "\n",
    "data_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inside fit transform\n",
      "Feature Gender\n",
      "mapping {0: 0, 1: 1}\n",
      "Feature Married\n",
      "mapping {0: 0, 1: 1}\n",
      "Feature Fraud_risk\n",
      "mapping {0: 0, 1: 1}\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "from Pipeline_LabelEncoder.sklearn_label_encoder import PipelineLabelEncoder\n",
    "preprocessed_data = PipelineLabelEncoder(columns = ['Gender','Married', 'Fraud_risk']).fit_transform(data_encoded)\n",
    "print('-------------------------')\n",
    "#print('validation data encoding')\n",
    "#validation_enc_data = PipelineLabelEncoder(columns = ['Gender','Married', 'Fraud_risk']).transform(validation_input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create binary label dataset that can be used by bias mitigation algorithms\n",
    "fraud_dataset = BinaryLabelDataset(favorable_label=favorable_label,\n",
    "                                unfavorable_label=unfavorable_label,\n",
    "                                df=preprocessed_data,\n",
    "                                label_names=['Fraud_risk'],\n",
    "                                protected_attribute_names=['Gender', 'Married'],\n",
    "                                unprivileged_protected_attributes=unprivileged_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Training Data Details"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of the training dataset (921, 3)\n",
      "Training data favorable label 1.0\n",
      "Training data unfavorable label 0.0\n",
      "Training data protected attribute ['Gender', 'Married']\n",
      "Training data privileged protected attribute (1:Male and 0:Female) [array([1.]), array([1.])]\n",
      "Training data unprivileged protected attribute (1:Male and 0:Female) [array([0.]), array([0.])]\n"
     ]
    }
   ],
   "source": [
    "display(Markdown(\"#### Training Data Details\"))\n",
    "print(\"shape of the training dataset\", fraud_dataset.features.shape)\n",
    "print(\"Training data favorable label\", fraud_dataset.favorable_label)\n",
    "print(\"Training data unfavorable label\", fraud_dataset.unfavorable_label)\n",
    "print(\"Training data protected attribute\", fraud_dataset.protected_attribute_names)\n",
    "print(\"Training data privileged protected attribute (1:Male and 0:Female)\", \n",
    "      fraud_dataset.privileged_protected_attributes)\n",
    "print(\"Training data unprivileged protected attribute (1:Male and 0:Female)\",\n",
    "      fraud_dataset.unprivileged_protected_attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud_dataset_train, fraud_dataset_test = fraud_dataset.split([0.9], shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Original training dataset"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: Difference in mean outcomes between unprivileged and privileged groups = -0.391761\n",
      "Test set: Difference in mean outcomes between unprivileged and privileged groups = -0.208075\n"
     ]
    }
   ],
   "source": [
    "# Metric for the original dataset\n",
    "metric_orig_train = BinaryLabelDatasetMetric(fraud_dataset_train, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "display(Markdown(\"#### Original training dataset\"))\n",
    "print(\"Train set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_orig_train.mean_difference())\n",
    "metric_orig_test = BinaryLabelDatasetMetric(fraud_dataset_test, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "print(\"Test set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_orig_test.mean_difference())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Scaled dataset - Verify that the scaling does not affect the group label statistics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: Difference in mean outcomes between unprivileged and privileged groups = -0.391761\n",
      "Test set: Difference in mean outcomes between unprivileged and privileged groups = -0.208075\n"
     ]
    }
   ],
   "source": [
    "min_max_scaler = MaxAbsScaler()\n",
    "fraud_dataset_train.features = min_max_scaler.fit_transform(fraud_dataset_train.features)\n",
    "fraud_dataset_test.features = min_max_scaler.transform(fraud_dataset_test.features)\n",
    "metric_scaled_train = BinaryLabelDatasetMetric(fraud_dataset_train, \n",
    "                             unprivileged_groups=unprivileged_groups,\n",
    "                             privileged_groups=privileged_groups)\n",
    "display(Markdown(\"#### Scaled dataset - Verify that the scaling does not affect the group label statistics\"))\n",
    "print(\"Train set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_scaled_train.mean_difference())\n",
    "metric_scaled_test = BinaryLabelDatasetMetric(fraud_dataset_test, \n",
    "                             unprivileged_groups=unprivileged_groups,\n",
    "                             privileged_groups=privileged_groups)\n",
    "print(\"Test set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_scaled_test.mean_difference())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build plan classifier without debiasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load post-processing algorithm that equalizes the odds\n",
    "# Learn parameters with debias set to False\n",
    "sess = tf.Session()\n",
    "#sess = tf.compat.v1.Session()\n",
    "plain_model = AdversarialDebiasing(privileged_groups = privileged_groups,\n",
    "                          unprivileged_groups = unprivileged_groups,\n",
    "                          scope_name='plain_classifier',\n",
    "                          debias=False,\n",
    "                          sess=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages/aif360/algorithms/inprocessing/adversarial_debiasing.py:137: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages/aif360/algorithms/inprocessing/adversarial_debiasing.py:141: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages/aif360/algorithms/inprocessing/adversarial_debiasing.py:84: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages/aif360/algorithms/inprocessing/adversarial_debiasing.py:89: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages/aif360/algorithms/inprocessing/adversarial_debiasing.py:159: The name tf.train.exponential_decay is deprecated. Please use tf.compat.v1.train.exponential_decay instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages/aif360/algorithms/inprocessing/adversarial_debiasing.py:161: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages/aif360/algorithms/inprocessing/adversarial_debiasing.py:165: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages/aif360/algorithms/inprocessing/adversarial_debiasing.py:187: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages/aif360/algorithms/inprocessing/adversarial_debiasing.py:188: The name tf.local_variables_initializer is deprecated. Please use tf.compat.v1.local_variables_initializer instead.\n",
      "\n",
      "epoch 0; iter: 0; batch classifier loss: 0.741976\n",
      "epoch 1; iter: 0; batch classifier loss: 0.695072\n",
      "epoch 2; iter: 0; batch classifier loss: 0.650911\n",
      "epoch 3; iter: 0; batch classifier loss: 0.618827\n",
      "epoch 4; iter: 0; batch classifier loss: 0.609861\n",
      "epoch 5; iter: 0; batch classifier loss: 0.602363\n",
      "epoch 6; iter: 0; batch classifier loss: 0.553024\n",
      "epoch 7; iter: 0; batch classifier loss: 0.516665\n",
      "epoch 8; iter: 0; batch classifier loss: 0.550386\n",
      "epoch 9; iter: 0; batch classifier loss: 0.544631\n",
      "epoch 10; iter: 0; batch classifier loss: 0.519097\n",
      "epoch 11; iter: 0; batch classifier loss: 0.508178\n",
      "epoch 12; iter: 0; batch classifier loss: 0.467921\n",
      "epoch 13; iter: 0; batch classifier loss: 0.434507\n",
      "epoch 14; iter: 0; batch classifier loss: 0.430098\n",
      "epoch 15; iter: 0; batch classifier loss: 0.422339\n",
      "epoch 16; iter: 0; batch classifier loss: 0.476755\n",
      "epoch 17; iter: 0; batch classifier loss: 0.424935\n",
      "epoch 18; iter: 0; batch classifier loss: 0.389450\n",
      "epoch 19; iter: 0; batch classifier loss: 0.385219\n",
      "epoch 20; iter: 0; batch classifier loss: 0.371752\n",
      "epoch 21; iter: 0; batch classifier loss: 0.372986\n",
      "epoch 22; iter: 0; batch classifier loss: 0.361450\n",
      "epoch 23; iter: 0; batch classifier loss: 0.398418\n",
      "epoch 24; iter: 0; batch classifier loss: 0.416664\n",
      "epoch 25; iter: 0; batch classifier loss: 0.374618\n",
      "epoch 26; iter: 0; batch classifier loss: 0.334579\n",
      "epoch 27; iter: 0; batch classifier loss: 0.316246\n",
      "epoch 28; iter: 0; batch classifier loss: 0.318755\n",
      "epoch 29; iter: 0; batch classifier loss: 0.377181\n",
      "epoch 30; iter: 0; batch classifier loss: 0.342933\n",
      "epoch 31; iter: 0; batch classifier loss: 0.368084\n",
      "epoch 32; iter: 0; batch classifier loss: 0.419054\n",
      "epoch 33; iter: 0; batch classifier loss: 0.392213\n",
      "epoch 34; iter: 0; batch classifier loss: 0.357927\n",
      "epoch 35; iter: 0; batch classifier loss: 0.419555\n",
      "epoch 36; iter: 0; batch classifier loss: 0.375561\n",
      "epoch 37; iter: 0; batch classifier loss: 0.335526\n",
      "epoch 38; iter: 0; batch classifier loss: 0.436809\n",
      "epoch 39; iter: 0; batch classifier loss: 0.362905\n",
      "epoch 40; iter: 0; batch classifier loss: 0.370575\n",
      "epoch 41; iter: 0; batch classifier loss: 0.441248\n",
      "epoch 42; iter: 0; batch classifier loss: 0.365211\n",
      "epoch 43; iter: 0; batch classifier loss: 0.371696\n",
      "epoch 44; iter: 0; batch classifier loss: 0.430379\n",
      "epoch 45; iter: 0; batch classifier loss: 0.351909\n",
      "epoch 46; iter: 0; batch classifier loss: 0.382154\n",
      "epoch 47; iter: 0; batch classifier loss: 0.334142\n",
      "epoch 48; iter: 0; batch classifier loss: 0.412523\n",
      "epoch 49; iter: 0; batch classifier loss: 0.446772\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<aif360.algorithms.inprocessing.adversarial_debiasing.AdversarialDebiasing at 0x7fef09cb6c90>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plain_model.fit(fraud_dataset_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply the plain model to test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_nodebiasing_train = plain_model.predict(fraud_dataset_train)\n",
    "dataset_nodebiasing_test = plain_model.predict(fraud_dataset_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics for the dataset from plain model (without debiasing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Model - without debiasing - dataset metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: Difference in mean outcomes between unprivileged and privileged groups = -0.530611\n",
      "Test set: Difference in mean outcomes between unprivileged and privileged groups = -0.380745\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Model - without debiasing - classification metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Classification accuracy = 0.892473\n",
      "Test set: Balanced classification accuracy = 0.880622\n",
      "Test set: Disparate impact = 0.477408\n",
      "Test set: Equal opportunity difference = -0.177778\n",
      "Test set: Average odds difference = -0.228889\n",
      "Test set: Theil_index = 0.057930\n"
     ]
    }
   ],
   "source": [
    "display(Markdown(\"#### Model - without debiasing - dataset metrics\"))\n",
    "metric_dataset_nodebiasing_train = BinaryLabelDatasetMetric(dataset_nodebiasing_train, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "\n",
    "print(\"Train set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_dataset_nodebiasing_train.mean_difference())\n",
    "\n",
    "metric_dataset_nodebiasing_test = BinaryLabelDatasetMetric(dataset_nodebiasing_test, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "\n",
    "print(\"Test set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_dataset_nodebiasing_test.mean_difference())\n",
    "\n",
    "display(Markdown(\"#### Model - without debiasing - classification metrics\"))\n",
    "classified_metric_nodebiasing_test = ClassificationMetric(fraud_dataset_test, \n",
    "                                                 dataset_nodebiasing_test,\n",
    "                                                 unprivileged_groups=unprivileged_groups,\n",
    "                                                 privileged_groups=privileged_groups)\n",
    "print(\"Test set: Classification accuracy = %f\" % classified_metric_nodebiasing_test.accuracy())\n",
    "TPR = classified_metric_nodebiasing_test.true_positive_rate()\n",
    "TNR = classified_metric_nodebiasing_test.true_negative_rate()\n",
    "bal_acc_nodebiasing_test = 0.5*(TPR+TNR)\n",
    "print(\"Test set: Balanced classification accuracy = %f\" % bal_acc_nodebiasing_test)\n",
    "print(\"Test set: Disparate impact = %f\" % classified_metric_nodebiasing_test.disparate_impact())\n",
    "print(\"Test set: Equal opportunity difference = %f\" % classified_metric_nodebiasing_test.equal_opportunity_difference())\n",
    "print(\"Test set: Average odds difference = %f\" % classified_metric_nodebiasing_test.average_odds_difference())\n",
    "print(\"Test set: Theil_index = %f\" % classified_metric_nodebiasing_test.theil_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply in-processing algorithm based on adversarial learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()\n",
    "tf.reset_default_graph()\n",
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learn parameters with debias set to True\n",
    "debiased_model = AdversarialDebiasing(privileged_groups = privileged_groups,\n",
    "                          unprivileged_groups = unprivileged_groups,\n",
    "                          scope_name='debiased_classifier',\n",
    "                          debias=True,\n",
    "                          sess=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0; iter: 0; batch classifier loss: 0.677075; batch adversarial loss: 0.819948\n",
      "epoch 1; iter: 0; batch classifier loss: 0.665931; batch adversarial loss: 0.815118\n",
      "epoch 2; iter: 0; batch classifier loss: 0.647304; batch adversarial loss: 0.813850\n",
      "epoch 3; iter: 0; batch classifier loss: 0.644438; batch adversarial loss: 0.808258\n",
      "epoch 4; iter: 0; batch classifier loss: 0.612280; batch adversarial loss: 0.817850\n",
      "epoch 5; iter: 0; batch classifier loss: 0.601025; batch adversarial loss: 0.823577\n",
      "epoch 6; iter: 0; batch classifier loss: 0.602548; batch adversarial loss: 0.802757\n",
      "epoch 7; iter: 0; batch classifier loss: 0.561226; batch adversarial loss: 0.795474\n",
      "epoch 8; iter: 0; batch classifier loss: 0.554748; batch adversarial loss: 0.789475\n",
      "epoch 9; iter: 0; batch classifier loss: 0.563382; batch adversarial loss: 0.800412\n",
      "epoch 10; iter: 0; batch classifier loss: 0.540931; batch adversarial loss: 0.788777\n",
      "epoch 11; iter: 0; batch classifier loss: 0.512059; batch adversarial loss: 0.779748\n",
      "epoch 12; iter: 0; batch classifier loss: 0.483869; batch adversarial loss: 0.790502\n",
      "epoch 13; iter: 0; batch classifier loss: 0.498710; batch adversarial loss: 0.801938\n",
      "epoch 14; iter: 0; batch classifier loss: 0.506458; batch adversarial loss: 0.764050\n",
      "epoch 15; iter: 0; batch classifier loss: 0.479398; batch adversarial loss: 0.778534\n",
      "epoch 16; iter: 0; batch classifier loss: 0.459932; batch adversarial loss: 0.797422\n",
      "epoch 17; iter: 0; batch classifier loss: 0.447250; batch adversarial loss: 0.794455\n",
      "epoch 18; iter: 0; batch classifier loss: 0.437220; batch adversarial loss: 0.775563\n",
      "epoch 19; iter: 0; batch classifier loss: 0.487675; batch adversarial loss: 0.766644\n",
      "epoch 20; iter: 0; batch classifier loss: 0.468904; batch adversarial loss: 0.776044\n",
      "epoch 21; iter: 0; batch classifier loss: 0.457095; batch adversarial loss: 0.759362\n",
      "epoch 22; iter: 0; batch classifier loss: 0.437609; batch adversarial loss: 0.773170\n",
      "epoch 23; iter: 0; batch classifier loss: 0.439324; batch adversarial loss: 0.751251\n",
      "epoch 24; iter: 0; batch classifier loss: 0.466393; batch adversarial loss: 0.764639\n",
      "epoch 25; iter: 0; batch classifier loss: 0.487005; batch adversarial loss: 0.748533\n",
      "epoch 26; iter: 0; batch classifier loss: 0.464429; batch adversarial loss: 0.740306\n",
      "epoch 27; iter: 0; batch classifier loss: 0.397893; batch adversarial loss: 0.739428\n",
      "epoch 28; iter: 0; batch classifier loss: 0.426453; batch adversarial loss: 0.739081\n",
      "epoch 29; iter: 0; batch classifier loss: 0.456230; batch adversarial loss: 0.729701\n",
      "epoch 30; iter: 0; batch classifier loss: 0.476655; batch adversarial loss: 0.728652\n",
      "epoch 31; iter: 0; batch classifier loss: 0.461911; batch adversarial loss: 0.707275\n",
      "epoch 32; iter: 0; batch classifier loss: 0.443439; batch adversarial loss: 0.728586\n",
      "epoch 33; iter: 0; batch classifier loss: 0.498218; batch adversarial loss: 0.722284\n",
      "epoch 34; iter: 0; batch classifier loss: 0.446416; batch adversarial loss: 0.720946\n",
      "epoch 35; iter: 0; batch classifier loss: 0.478449; batch adversarial loss: 0.701717\n",
      "epoch 36; iter: 0; batch classifier loss: 0.498248; batch adversarial loss: 0.702406\n",
      "epoch 37; iter: 0; batch classifier loss: 0.376640; batch adversarial loss: 0.707345\n",
      "epoch 38; iter: 0; batch classifier loss: 0.448015; batch adversarial loss: 0.688885\n",
      "epoch 39; iter: 0; batch classifier loss: 0.502922; batch adversarial loss: 0.680792\n",
      "epoch 40; iter: 0; batch classifier loss: 0.420004; batch adversarial loss: 0.694323\n",
      "epoch 41; iter: 0; batch classifier loss: 0.373380; batch adversarial loss: 0.694486\n",
      "epoch 42; iter: 0; batch classifier loss: 0.350538; batch adversarial loss: 0.685714\n",
      "epoch 43; iter: 0; batch classifier loss: 0.373963; batch adversarial loss: 0.685520\n",
      "epoch 44; iter: 0; batch classifier loss: 0.362602; batch adversarial loss: 0.681911\n",
      "epoch 45; iter: 0; batch classifier loss: 0.519748; batch adversarial loss: 0.674026\n",
      "epoch 46; iter: 0; batch classifier loss: 0.459189; batch adversarial loss: 0.676379\n",
      "epoch 47; iter: 0; batch classifier loss: 0.375871; batch adversarial loss: 0.670941\n",
      "epoch 48; iter: 0; batch classifier loss: 0.393712; batch adversarial loss: 0.667312\n",
      "epoch 49; iter: 0; batch classifier loss: 0.419519; batch adversarial loss: 0.666416\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<aif360.algorithms.inprocessing.adversarial_debiasing.AdversarialDebiasing at 0x7fef0cc01e50>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "debiased_model.fit(fraud_dataset_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply the plain model to test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_debiasing_train = debiased_model.predict(fraud_dataset_train)\n",
    "dataset_debiasing_test = debiased_model.predict(fraud_dataset_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Model - without debiasing - dataset metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: Difference in mean outcomes between unprivileged and privileged groups = -0.530611\n",
      "Test set: Difference in mean outcomes between unprivileged and privileged groups = -0.380745\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Model - with debiasing - dataset metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: Difference in mean outcomes between unprivileged and privileged groups = -0.251914\n",
      "Test set: Difference in mean outcomes between unprivileged and privileged groups = -0.020497\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Model - without debiasing - classification metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Classification accuracy = 0.892473\n",
      "Test set: Balanced classification accuracy = 0.880622\n",
      "Test set: Disparate impact = 0.477408\n",
      "Test set: Equal opportunity difference = -0.177778\n",
      "Test set: Average odds difference = -0.228889\n",
      "Test set: Theil_index = 0.057930\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "#### Model - with debiasing - classification metrics"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set: Classification accuracy = 0.860215\n",
      "Test set: Balanced classification accuracy = 0.857416\n",
      "Test set: Disparate impact = 0.965005\n",
      "Test set: Equal opportunity difference = 0.033333\n",
      "Test set: Average odds difference = 0.130513\n",
      "Test set: Theil_index = 0.101221\n"
     ]
    }
   ],
   "source": [
    "# Metrics for the dataset from plain model (without debiasing)\n",
    "display(Markdown(\"#### Model - without debiasing - dataset metrics\"))\n",
    "print(\"Train set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_dataset_nodebiasing_train.mean_difference())\n",
    "print(\"Test set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_dataset_nodebiasing_test.mean_difference())\n",
    "\n",
    "# Metrics for the dataset from model with debiasing\n",
    "display(Markdown(\"#### Model - with debiasing - dataset metrics\"))\n",
    "metric_dataset_debiasing_train = BinaryLabelDatasetMetric(dataset_debiasing_train, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "\n",
    "print(\"Train set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_dataset_debiasing_train.mean_difference())\n",
    "\n",
    "metric_dataset_debiasing_test = BinaryLabelDatasetMetric(dataset_debiasing_test, \n",
    "                                             unprivileged_groups=unprivileged_groups,\n",
    "                                             privileged_groups=privileged_groups)\n",
    "\n",
    "print(\"Test set: Difference in mean outcomes between unprivileged and privileged groups = %f\" % metric_dataset_debiasing_test.mean_difference())\n",
    "\n",
    "\n",
    "\n",
    "display(Markdown(\"#### Model - without debiasing - classification metrics\"))\n",
    "print(\"Test set: Classification accuracy = %f\" % classified_metric_nodebiasing_test.accuracy())\n",
    "TPR = classified_metric_nodebiasing_test.true_positive_rate()\n",
    "TNR = classified_metric_nodebiasing_test.true_negative_rate()\n",
    "bal_acc_nodebiasing_test = 0.5*(TPR+TNR)\n",
    "print(\"Test set: Balanced classification accuracy = %f\" % bal_acc_nodebiasing_test)\n",
    "print(\"Test set: Disparate impact = %f\" % classified_metric_nodebiasing_test.disparate_impact())\n",
    "print(\"Test set: Equal opportunity difference = %f\" % classified_metric_nodebiasing_test.equal_opportunity_difference())\n",
    "print(\"Test set: Average odds difference = %f\" % classified_metric_nodebiasing_test.average_odds_difference())\n",
    "print(\"Test set: Theil_index = %f\" % classified_metric_nodebiasing_test.theil_index())\n",
    "\n",
    "\n",
    "\n",
    "display(Markdown(\"#### Model - with debiasing - classification metrics\"))\n",
    "classified_metric_debiasing_test = ClassificationMetric(fraud_dataset_test, \n",
    "                                                 dataset_debiasing_test,\n",
    "                                                 unprivileged_groups=unprivileged_groups,\n",
    "                                                 privileged_groups=privileged_groups)\n",
    "print(\"Test set: Classification accuracy = %f\" % classified_metric_debiasing_test.accuracy())\n",
    "TPR = classified_metric_debiasing_test.true_positive_rate()\n",
    "TNR = classified_metric_debiasing_test.true_negative_rate()\n",
    "bal_acc_debiasing_test = 0.5*(TPR+TNR)\n",
    "print(\"Test set: Balanced classification accuracy = %f\" % bal_acc_debiasing_test)\n",
    "print(\"Test set: Disparate impact = %f\" % classified_metric_debiasing_test.disparate_impact())\n",
    "print(\"Test set: Equal opportunity difference = %f\" % classified_metric_debiasing_test.equal_opportunity_difference())\n",
    "print(\"Test set: Average odds difference = %f\" % classified_metric_debiasing_test.average_odds_difference())\n",
    "print(\"Test set: Theil_index = %f\" % classified_metric_debiasing_test.theil_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We have observed how to use AI 360 fairness toolkit to eliminate the bias during preprocessing & inprocessing stages of model building & development."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
